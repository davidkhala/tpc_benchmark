{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import config, h_setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/colin/code/bq_snowflake_benchmark/h/2.18.0_rc2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.fp_h_src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = config.fp_h_src + config.sep + \"dbgen\""
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "os.environ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this_'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"this_that\".rstrip(\"that\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def run_qgen(scale=1, seed=None, verbose=False):\n",
    "\n",
    "    fp = config.fp_h_src + config.sep + \"dbgen\"\n",
    "\n",
    "    env_vars = dict(os.environ)\n",
    "    env_vars[\"DSS_PATH\"] = config.fp_h_data_out + config.sep + str(scale) + \"GB\"\n",
    "    env_vars[\"DSS_QUERY\"] = fp + config.sep + \"queries\"\n",
    "\n",
    "    cmd = [\"./qgen\"]\n",
    "\n",
    "    if seed is not None:\n",
    "        cmd = cmd + [\"-r\", str(seed)]\n",
    "    \n",
    "    pipe = subprocess.run(cmd, \n",
    "                          stdout=subprocess.PIPE, \n",
    "                          stderr=subprocess.PIPE, \n",
    "                          cwd=fp,\n",
    "                          env=env_vars)\n",
    "\n",
    "    std_out = pipe.stdout.decode(\"utf-8\")\n",
    "    err_out = pipe.stderr.decode(\"utf-8\")\n",
    "\n",
    "    if verbose:\n",
    "        if len(std_out) > 0:\n",
    "            print(\"Standard Out:\")\n",
    "            print(\"=============\")\n",
    "            print(std_out)\n",
    "        if len(err_out) > 0:\n",
    "            print(\"Error Out\")\n",
    "            print(\"=========\")\n",
    "            print(err_out)\n",
    "    \n",
    "    std_out = std_out.split(\"\\n\")\n",
    "    std_out_new = []\n",
    "    c = 0\n",
    "    for line in std_out:\n",
    "        line = line.rstrip(\"\\r\")\n",
    "        line = line.rstrip(\"\\n\")\n",
    "        c += 1\n",
    "        if c > 3:\n",
    "            std_out_new.append(line)\n",
    "    std_out = std_out_new\n",
    "    std_out = \"\\n\".join(std_out)\n",
    "    return std_out, err_out\n",
    "s, e = foo()\n",
    "print(s)\n",
    "print(e)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "def rewrite_schema(filepath_in, filepath_out, dataset_name):\n",
    "    \"\"\"Convert the sample implementation of the logical schema as described in TPC-DS Specification V1.0.0L , specifications.pdf, pg 99, Appendix A and contained in  tpc_rool/tools/tpcds.sql.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    file_path_in : str, path to tpcds.sql file\n",
    "    file_path_out : str, path to write BigQuery formatted table schema, named 'tpcds_bq.sql'\n",
    "    dataset_name : str, name of BigQuery Dataset to append to existing table names\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    None, only writes to file\n",
    "    \"\"\"\n",
    "\n",
    "    # note that leading and trailing whitespace is used to find only table datatype strings\n",
    "    dtype_mapper = {r'  decimal\\(\\d+,\\d+\\)  ': r'  FLOAT64  ',\n",
    "                    r'  varchar\\(\\d+\\)  ':     r'  STRING  ',\n",
    "                    r'  char\\(\\d+\\)  ':        r'  STRING  ',\n",
    "                    r'  integer  ':            r'  INT64  ',\n",
    "                    # the following are just to have consistent UPPERCASE formatting\n",
    "                    r'  time  ':               r'  TIME  ',\n",
    "                    r'  date  ':               r'  DATE  '\n",
    "                   }\n",
    "    \n",
    "    text = open(filepath_in).read()\n",
    "    \n",
    "    for k, v in dtype_mapper.items():\n",
    "        regex = re.compile(k)\n",
    "        text = regex.sub(v, text)\n",
    "\n",
    "    text_list_in = text.split(\"\\n\")\n",
    "    text_list_out = []\n",
    "    \n",
    "    for line in text_list_in:\n",
    "        if \"primary key\" in line:\n",
    "            continue\n",
    "        if \"create table\" in line:\n",
    "            split_line = line.split()\n",
    "            table_name = split_line[2]\n",
    "            new_line = split_line[:2] + [dataset_name + \".\" + table_name]\n",
    "            new_line = \" \".join(new_line)\n",
    "            text_list_out.append(new_line)\n",
    "        else:\n",
    "            text_list_out.append(line)\n",
    "    \n",
    "    text = \"\\n\".join(text_list_out)\n",
    "    \n",
    "    open(filepath_out, \"w\").write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(1, 23))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select\n",
      "\tl_returnflag,\n",
      "\tl_linestatus,\n",
      "\tsum(l_quantity) as sum_qty,\n",
      "\tsum(l_extendedprice) as sum_base_price,\n",
      "\tsum(l_extendedprice * (1 - l_discount)) as sum_disc_price,\n",
      "\tsum(l_extendedprice * (1 - l_discount) * (1 + l_tax)) as sum_charge,\n",
      "\tavg(l_quantity) as avg_qty,\n",
      "\tavg(l_extendedprice) as avg_price,\n",
      "\tavg(l_discount) as avg_disc,\n",
      "\tcount(*) as count_order\n",
      "from\n",
      "\tlineitem\n",
      "where\n",
      "\tl_shipdate <= date '1998-12-01' - interval '103' day (3)\n",
      "group by\n",
      "\tl_returnflag,\n",
      "\tl_linestatus\n",
      "order by\n",
      "\tl_returnflag,\n",
      "\tl_linestatus;\n",
      "set rowcount -1\n",
      "go\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reload(h_setup)\n",
    "s, e = h_setup.run_qgen(1, scale=1, seed=13, verbose=False)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
