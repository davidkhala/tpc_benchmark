{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TPC Dataset Import\n",
    "Import data for TPC test from GCS into Snowflake database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import config, sf, datetime\n",
    "\n",
    "# In \"Dry Run\" mode we generate and print SQL queries but not run them.\n",
    "# You can manually run them in \"workbench\" if you want\n",
    "DRY_RUN = False\n",
    "TEST = sf.TEST_H  # we want to run TPC-H\n",
    "SIZE = '10000GB'  # dataset size to use in test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "`Note: that we use configuration data from config.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Snowflake WAREHOUSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preparing to open connection to Snowflake\n",
      "using config: user:sadadauren, pass: Test1234!, account: sl19096.us-central1.gcp\n",
      "connection opened\n",
      "running query: USE ROLE ACCOUNTADMIN\n",
      "result: Statement executed successfully.\n",
      "running query: ALTER WAREHOUSE TEST2 RESUME;\n",
      "Error running query 090063 (22000): Invalid state. Warehouse 'TEST2' cannot be resumed since it is not suspended.\n",
      "warehouse start: None\n",
      "running query: USE WAREHOUSE TEST2\n",
      "result: Statement executed successfully.\n",
      "running query: CREATE DATABASE IF NOT EXISTS h_10000GB\n",
      "result: H_10000GB already exists, statement succeeded.\n",
      "running query: USE DATABASE h_10000GB\n",
      "result: Statement executed successfully.\n"
     ]
    }
   ],
   "source": [
    "# initiate SnowflakeHelper with Test type and dataset size specified\n",
    "sf_helper = sf.SnowflakeHelper(TEST, SIZE, config)\n",
    "\n",
    "# start Warehouse\n",
    "sf_helper.warehouse_start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup STAGE: Link to GCS data source and stages files for uploading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--creating named file format: \"@csv_file_format\"\n",
      "running query: create or replace file format csv_file_format\n",
      "            type = csv\n",
      "            field_delimiter = '|'\n",
      "            skip_header = 1\n",
      "            null_if = ('NULL', 'null')\n",
      "            empty_field_as_null = true\n",
      "            encoding = 'iso-8859-1' \n",
      "            compression = none;\n",
      "result File format CSV_FILE_FORMAT successfully created.\n",
      "\n",
      "\n",
      "--done creating named file format\n",
      "\n",
      "\n",
      "--integrating \"gcs_h_10000GB_integration\" ... \n",
      "\n",
      "\n",
      "--creating storage integration: \"gcs_h_10000GB_integration\"\n",
      "running query: CREATE STORAGE INTEGRATION gcs_h_10000GB_integration TYPE=EXTERNAL_STAGE STORAGE_PROVIDER=GCS ENABLED=TRUE STORAGE_ALLOWED_LOCATIONS=('gcs://tpc-benchmark-5947/');\n",
      "result Integration GCS_H_10000GB_INTEGRATION successfully created.\n",
      "\n",
      "\n",
      "--finished creating storage integration\n",
      "running query: GRANT CREATE STAGE on schema public to ROLE ACCOUNTADMIN;\n",
      "result Statement executed successfully.\n",
      "running query: GRANT USAGE on INTEGRATION gcs_h_10000GB_integration to ROLE ACCOUNTADMIN;\n",
      "result Statement executed successfully.\n",
      "running query: CREATE STAGE gcs_h_10000GB_integration_stage URL='gcs://tpc-benchmark-5947' STORAGE_INTEGRATION=gcs_h_10000GB_integration FILE_FORMAT=csv_file_format;\n",
      "result Stage area GCS_H_10000GB_INTEGRATION_STAGE successfully created.\n",
      "running query: list  @gcs_h_10000GB_integration_stage;\n",
      "result gcs://tpc-benchmark-5947/_data_ds_1000GB_catalog_returns_15_96.dat\n",
      "--finished staging \"gcs_h_10000GB_integration\"\n",
      "\n",
      "\n",
      "integrated with gcs: gcs_h_10000GB_integration\n"
     ]
    }
   ],
   "source": [
    "if not sf_helper.is_integrated():\n",
    "    # integrate Snoflake with GCS.\n",
    "    integration_id = sf_helper.create_integration(is_dry_run=DRY_RUN)\n",
    "    print(f'integrated with gcs: {integration_id}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test STAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--listing stage: \"@gcs_h_10000GB_integration_stage\"\n",
      "nation:\n",
      "\tgcs://tpc-benchmark-5947/h_10000GB_nation.tbl\n",
      "\tmissing 95 files\n",
      "\n",
      "\n",
      "lineitem:\n",
      "\tgcs://tpc-benchmark-5947/h_10000GB_lineitem.tbl.1\n",
      "\tgcs://tpc-benchmark-5947/h_10000GB_lineitem.tbl.2\n",
      "\tgcs://tpc-benchmark-5947/h_10000GB_lineitem.tbl.3\n",
      "\tgcs://tpc-benchmark-5947/h_10000GB_lineitem.tbl.4\n",
      "\tgcs://tpc-benchmark-5947/h_10000GB_lineitem.tbl.5\n",
      "\tgcs://tpc-benchmark-5947/h_10000GB_lineitem.tbl.6\n",
      "\tgcs://tpc-benchmark-5947/h_10000GB_lineitem.tbl.7\n",
      "\tgcs://tpc-benchmark-5947/h_10000GB_lineitem.tbl.8\n",
      "\tgcs://tpc-benchmark-5947/h_10000GB_lineitem.tbl.9\n",
      "\tmissing 87 files\n",
      "\n",
      "\n",
      "customer:\n",
      "\tgcs://tpc-benchmark-5947/h_10000GB_customer.tbl.1\n",
      "\tgcs://tpc-benchmark-5947/h_10000GB_customer.tbl.2\n",
      "\tgcs://tpc-benchmark-5947/h_10000GB_customer.tbl.3\n",
      "\tgcs://tpc-benchmark-5947/h_10000GB_customer.tbl.4\n",
      "\tgcs://tpc-benchmark-5947/h_10000GB_customer.tbl.5\n",
      "\tgcs://tpc-benchmark-5947/h_10000GB_customer.tbl.6\n",
      "\tgcs://tpc-benchmark-5947/h_10000GB_customer.tbl.7\n",
      "\tgcs://tpc-benchmark-5947/h_10000GB_customer.tbl.8\n",
      "\tgcs://tpc-benchmark-5947/h_10000GB_customer.tbl.9\n",
      "\tmissing 87 files\n",
      "\n",
      "\n",
      "orders:\n",
      "\tgcs://tpc-benchmark-5947/h_10000GB_orders.tbl.1\n",
      "\tgcs://tpc-benchmark-5947/h_10000GB_orders.tbl.2\n",
      "\tgcs://tpc-benchmark-5947/h_10000GB_orders.tbl.3\n",
      "\tgcs://tpc-benchmark-5947/h_10000GB_orders.tbl.4\n",
      "\tgcs://tpc-benchmark-5947/h_10000GB_orders.tbl.5\n",
      "\tgcs://tpc-benchmark-5947/h_10000GB_orders.tbl.6\n",
      "\tgcs://tpc-benchmark-5947/h_10000GB_orders.tbl.7\n",
      "\tgcs://tpc-benchmark-5947/h_10000GB_orders.tbl.8\n",
      "\tgcs://tpc-benchmark-5947/h_10000GB_orders.tbl.9\n",
      "\tmissing 87 files\n",
      "\n",
      "\n",
      "part:\n",
      "\tgcs://tpc-benchmark-5947/h_10000GB_part.tbl.1\n",
      "\tgcs://tpc-benchmark-5947/h_10000GB_part.tbl.2\n",
      "\tgcs://tpc-benchmark-5947/h_10000GB_part.tbl.3\n",
      "\tgcs://tpc-benchmark-5947/h_10000GB_part.tbl.4\n",
      "\tgcs://tpc-benchmark-5947/h_10000GB_part.tbl.5\n",
      "\tgcs://tpc-benchmark-5947/h_10000GB_part.tbl.6\n",
      "\tgcs://tpc-benchmark-5947/h_10000GB_part.tbl.7\n",
      "\tgcs://tpc-benchmark-5947/h_10000GB_part.tbl.8\n",
      "\tgcs://tpc-benchmark-5947/h_10000GB_part.tbl.9\n",
      "\tmissing 87 files\n",
      "\n",
      "\n",
      "partsupp:\n",
      "\tgcs://tpc-benchmark-5947/h_10000GB_partsupp.tbl.1\n",
      "\tgcs://tpc-benchmark-5947/h_10000GB_partsupp.tbl.2\n",
      "\tgcs://tpc-benchmark-5947/h_10000GB_partsupp.tbl.3\n",
      "\tgcs://tpc-benchmark-5947/h_10000GB_partsupp.tbl.4\n",
      "\tgcs://tpc-benchmark-5947/h_10000GB_partsupp.tbl.5\n",
      "\tgcs://tpc-benchmark-5947/h_10000GB_partsupp.tbl.6\n",
      "\tgcs://tpc-benchmark-5947/h_10000GB_partsupp.tbl.7\n",
      "\tgcs://tpc-benchmark-5947/h_10000GB_partsupp.tbl.8\n",
      "\tgcs://tpc-benchmark-5947/h_10000GB_partsupp.tbl.9\n",
      "\tmissing 87 files\n",
      "\n",
      "\n",
      "region:\n",
      "\tgcs://tpc-benchmark-5947/h_10000GB_region.tbl\n",
      "\tmissing 95 files\n",
      "\n",
      "\n",
      "supplier:\n",
      "\tgcs://tpc-benchmark-5947/h_10000GB_supplier.tbl.1\n",
      "\tgcs://tpc-benchmark-5947/h_10000GB_supplier.tbl.2\n",
      "\tgcs://tpc-benchmark-5947/h_10000GB_supplier.tbl.3\n",
      "\tgcs://tpc-benchmark-5947/h_10000GB_supplier.tbl.4\n",
      "\tgcs://tpc-benchmark-5947/h_10000GB_supplier.tbl.5\n",
      "\tgcs://tpc-benchmark-5947/h_10000GB_supplier.tbl.6\n",
      "\tgcs://tpc-benchmark-5947/h_10000GB_supplier.tbl.7\n",
      "\tgcs://tpc-benchmark-5947/h_10000GB_supplier.tbl.8\n",
      "\tgcs://tpc-benchmark-5947/h_10000GB_supplier.tbl.9\n",
      "\tmissing 87 files\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "db_files = sf_helper.list_integration(integration_id)\n",
    "for table, files in db_files.items():\n",
    "    print(f'{table}:')\n",
    "    for file in files:\n",
    "        print(f'\\t{file}')\n",
    "    print(f'\\tmissing {sf_helper.gcs_file_range - len(files)} files\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create tables in Snowflake if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--pushing schema: \"/home/vagrant/bq_snowflake_benchmark/h/2.18.0_rc2/dbgen/dss.ddl\"\n",
      "running query: -- Sccsid:     @(#)dss.ddl\t2.1.8.1\n",
      "CREATE TABLE NATION  ( N_NATIONKEY  INTEGER NOT NULL,\n",
      "                            N_NAME       CHAR(25) NOT NULL,\n",
      "                            N_REGIONKEY  INTEGER NOT NULL,\n",
      "                            N_COMMENT    VARCHAR(152));\n",
      "\n",
      "result Table NATION successfully created.\n",
      "running query: \n",
      "CREATE TABLE REGION  ( R_REGIONKEY  INTEGER NOT NULL,\n",
      "                            R_NAME       CHAR(25) NOT NULL,\n",
      "                            R_COMMENT    VARCHAR(152));\n",
      "\n",
      "result Table REGION successfully created.\n",
      "running query: \n",
      "CREATE TABLE PART  ( P_PARTKEY     INTEGER NOT NULL,\n",
      "                          P_NAME        VARCHAR(55) NOT NULL,\n",
      "                          P_MFGR        CHAR(25) NOT NULL,\n",
      "                          P_BRAND       CHAR(10) NOT NULL,\n",
      "                          P_TYPE        VARCHAR(25) NOT NULL,\n",
      "                          P_SIZE        INTEGER NOT NULL,\n",
      "                          P_CONTAINER   CHAR(10) NOT NULL,\n",
      "                          P_RETAILPRICE DECIMAL(15,2) NOT NULL,\n",
      "                          P_COMMENT     VARCHAR(23) NOT NULL );\n",
      "\n",
      "result Table PART successfully created.\n",
      "running query: \n",
      "CREATE TABLE SUPPLIER ( S_SUPPKEY     INTEGER NOT NULL,\n",
      "                             S_NAME        CHAR(25) NOT NULL,\n",
      "                             S_ADDRESS     VARCHAR(40) NOT NULL,\n",
      "                             S_NATIONKEY   INTEGER NOT NULL,\n",
      "                             S_PHONE       CHAR(15) NOT NULL,\n",
      "                             S_ACCTBAL     DECIMAL(15,2) NOT NULL,\n",
      "                             S_COMMENT     VARCHAR(101) NOT NULL);\n",
      "\n",
      "result Table SUPPLIER successfully created.\n",
      "running query: \n",
      "CREATE TABLE PARTSUPP ( PS_PARTKEY     INTEGER NOT NULL,\n",
      "                             PS_SUPPKEY     INTEGER NOT NULL,\n",
      "                             PS_AVAILQTY    INTEGER NOT NULL,\n",
      "                             PS_SUPPLYCOST  DECIMAL(15,2)  NOT NULL,\n",
      "                             PS_COMMENT     VARCHAR(199) NOT NULL );\n",
      "\n",
      "result Table PARTSUPP successfully created.\n",
      "running query: \n",
      "CREATE TABLE CUSTOMER ( C_CUSTKEY     INTEGER NOT NULL,\n",
      "                             C_NAME        VARCHAR(25) NOT NULL,\n",
      "                             C_ADDRESS     VARCHAR(40) NOT NULL,\n",
      "                             C_NATIONKEY   INTEGER NOT NULL,\n",
      "                             C_PHONE       CHAR(15) NOT NULL,\n",
      "                             C_ACCTBAL     DECIMAL(15,2)   NOT NULL,\n",
      "                             C_MKTSEGMENT  CHAR(10) NOT NULL,\n",
      "                             C_COMMENT     VARCHAR(117) NOT NULL);\n",
      "\n",
      "result Table CUSTOMER successfully created.\n",
      "running query: \n",
      "CREATE TABLE ORDERS  ( O_ORDERKEY       INTEGER NOT NULL,\n",
      "                           O_CUSTKEY        INTEGER NOT NULL,\n",
      "                           O_ORDERSTATUS    CHAR(1) NOT NULL,\n",
      "                           O_TOTALPRICE     DECIMAL(15,2) NOT NULL,\n",
      "                           O_ORDERDATE      DATE NOT NULL,\n",
      "                           O_ORDERPRIORITY  CHAR(15) NOT NULL,  \n",
      "                           O_CLERK          CHAR(15) NOT NULL, \n",
      "                           O_SHIPPRIORITY   INTEGER NOT NULL,\n",
      "                           O_COMMENT        VARCHAR(79) NOT NULL);\n",
      "\n",
      "result Table ORDERS successfully created.\n",
      "running query: \n",
      "CREATE TABLE LINEITEM ( L_ORDERKEY    INTEGER NOT NULL,\n",
      "                             L_PARTKEY     INTEGER NOT NULL,\n",
      "                             L_SUPPKEY     INTEGER NOT NULL,\n",
      "                             L_LINENUMBER  INTEGER NOT NULL,\n",
      "                             L_QUANTITY    DECIMAL(15,2) NOT NULL,\n",
      "                             L_EXTENDEDPRICE  DECIMAL(15,2) NOT NULL,\n",
      "                             L_DISCOUNT    DECIMAL(15,2) NOT NULL,\n",
      "                             L_TAX         DECIMAL(15,2) NOT NULL,\n",
      "                             L_RETURNFLAG  CHAR(1) NOT NULL,\n",
      "                             L_LINESTATUS  CHAR(1) NOT NULL,\n",
      "                             L_SHIPDATE    DATE NOT NULL,\n",
      "                             L_COMMITDATE  DATE NOT NULL,\n",
      "                             L_RECEIPTDATE DATE NOT NULL,\n",
      "                             L_SHIPINSTRUCT CHAR(25) NOT NULL,\n",
      "                             L_SHIPMODE     CHAR(10) NOT NULL,\n",
      "                             L_COMMENT      VARCHAR(44) NOT NULL);\n",
      "\n",
      "result Table LINEITEM successfully created.\n",
      "\n",
      "\n",
      "--finished pushing schema\n"
     ]
    }
   ],
   "source": [
    "if not sf_helper.is_integrated():\n",
    "    sf_helper.create_schema(is_dry_run=DRY_RUN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Import Data from STAGE to target table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to import table: nation\n",
      "\timporting file: gcs://tpc-benchmark-5947/h_10000GB_nation.tbl\n",
      "running query: copy into nation from 'gcs://tpc-benchmark-5947/h_10000GB_nation.tbl' storage_integration=gcs_h_10000GB_integration file_format=(format_name=csv_file_format);\n",
      "result gcs://tpc-benchmark-5947/h_10000GB_nation.tbl\n",
      "\tfinished @ 00:26:36.837355\n",
      "Starting to import table: lineitem\n",
      "\timporting file: gcs://tpc-benchmark-5947/h_10000GB_lineitem.tbl.1\n",
      "running query: copy into lineitem from 'gcs://tpc-benchmark-5947/h_10000GB_lineitem.tbl.1' storage_integration=gcs_h_10000GB_integration file_format=(format_name=csv_file_format);\n"
     ]
    }
   ],
   "source": [
    "for table, files in db_files.items():\n",
    "    print(f'Starting to import table: {table}')\n",
    "    for file in sorted(files):\n",
    "        print(f'\\timporting file: {file}')\n",
    "        sf_helper.import_data(table, file, integration_id)\n",
    "        print(f'\\tfinished @ {datetime.datetime.now().time()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Suspend WAREHOUSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warehouse suspend: Statement executed successfully.\n"
     ]
    }
   ],
   "source": [
    "sf_helper.warehouse_suspend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}